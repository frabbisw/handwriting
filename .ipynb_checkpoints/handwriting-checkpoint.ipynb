{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8660080a10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAELCAYAAAAP/iu7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBPf/AZ0MD6cAr47pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86420923c8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      torch.save(network.state_dict(), 'files/model.pth')\n",
    "      torch.save(optimizer.state_dict(), 'files/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabbi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/rabbi/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3004, Accuracy: 751/10000 (7%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.268457\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.268337\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.274000\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.251669\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.236826\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.223578\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.153432\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.096480\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.974480\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 1.944769\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.839859\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.767560\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.698696\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.683218\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.504576\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.390305\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.288033\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.330192\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.279881\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.235909\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.929160\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.403910\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.964923\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.107991\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.951868\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.047118\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.943156\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.835861\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.118890\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.651354\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.937120\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.788885\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.804054\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.761060\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.938306\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.620923\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.866454\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.637064\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.820755\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.835638\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.780326\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.717860\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.760290\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.732038\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.792407\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.717085\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.654979\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 1.035709\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.669501\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.901808\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.721920\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.692817\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.565244\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.474666\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.769211\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.473245\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.764203\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.338054\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.407062\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.565742\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.726373\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.434193\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.507312\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.599376\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.450341\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.411023\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.599571\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.604140\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.563987\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.498749\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.596781\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.706555\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.581650\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.861594\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.385662\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.473041\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.363285\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.595440\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.389879\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.379682\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.807775\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.465302\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.651214\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.770972\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.561776\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.444570\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.720846\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.465988\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.528196\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.551112\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.342349\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.494260\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.327837\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.479886\n",
      "\n",
      "Test set: Avg. loss: 0.1977, Accuracy: 9438/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.564135\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.303184\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.387638\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.296676\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.456380\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.681297\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.532839\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.450376\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.386649\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.478698\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.515907\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.405081\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.313718\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.348374\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.404361\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.390931\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.407438\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.598911\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.558244\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.505248\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.404336\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.483715\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.377044\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.328793\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.576501\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.389636\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.553879\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.388083\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.339585\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.380553\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.492008\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.350103\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.413656\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.714365\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.411749\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.412559\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.469358\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.433912\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.333452\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.337875\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.472762\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.336779\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.417194\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.380499\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.319719\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.470890\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.446142\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.668894\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.362302\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.396191\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.438560\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.332919\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.287437\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.386833\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.404504\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.614837\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.232742\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.509723\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.391423\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.354818\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.209936\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.319474\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.377236\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.351062\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.350311\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.322962\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.185142\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.226039\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.375794\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.412710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.444147\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.461082\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.453625\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.245011\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.284468\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.511315\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.345479\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.369339\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.309933\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.299410\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.427823\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.194481\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.399220\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.419703\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.296774\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.323996\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.357391\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.631218\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.331653\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.576029\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.384902\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.289487\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.203663\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.334206\n",
      "\n",
      "Test set: Avg. loss: 0.1271, Accuracy: 9612/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.288768\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.311541\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.398601\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.279929\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.392769\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.444696\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.415072\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.147815\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.245645\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.446095\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.349339\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.286519\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.382033\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.233884\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.389960\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.374991\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.423054\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.329017\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.259290\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.435035\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.294662\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.197742\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.215279\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.269475\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.166737\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.408193\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.287199\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.475736\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.270371\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.171509\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.573894\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.233471\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.336190\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.328865\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.277979\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.354589\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.442299\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.305073\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.317607\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.131832\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.283706\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.453101\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.280321\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.402127\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.236687\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.150232\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.201413\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.232665\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.314725\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.333739\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.320168\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.369024\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.346263\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.196277\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.297682\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.166755\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.325939\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.181615\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.417314\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.295232\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.199669\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.363849\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.141356\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.275506\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.312512\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.154907\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.196131\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.208602\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.262733\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.304261\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.236765\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.250221\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.264380\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.496724\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.354672\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.407058\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.231857\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.155112\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.458785\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.326358\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.272395\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.239137\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.224874\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.229134\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.415202\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.456712\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.287617\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.245424\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.310519\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.312146\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.196998\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.105091\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.182131\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.322856\n",
      "\n",
      "Test set: Avg. loss: 0.0935, Accuracy: 9723/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabbi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  output = network(example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAELCAYAAAAP/iu7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAADRUWwAANFRbAAA0f0/OX4mXCTo0ggAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86423f05c0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continued_network = Net()\n",
    "continued_optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                                momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabbi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.333328\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.310161\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.185264\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.145248\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.362089\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.589780\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.279127\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.260714\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.328563\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.235462\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.506299\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.206442\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.256710\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.173314\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.307480\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.164490\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.161419\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.253694\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.338847\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.322857\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.300243\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.396310\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.248854\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.371742\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.085546\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.208611\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.311938\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.193704\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.225661\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.190754\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.166584\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.095321\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.467920\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.270295\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.377692\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.186386\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.298230\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.185091\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.252754\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.167593\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.201256\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.262132\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.376078\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.221911\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.081481\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.373705\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.357460\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.132960\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.313014\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.325375\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.088427\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.238131\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.175419\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.430857\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.334059\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.252621\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.352760\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.606042\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.142140\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.316857\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.236952\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.112326\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.168650\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.145153\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.111905\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.250744\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.159399\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.399148\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.232618\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.445437\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.145374\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.278409\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.298391\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.203395\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.340411\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.298816\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.155790\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.278076\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.164392\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.198200\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.444911\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.184231\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.209758\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.177134\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.191313\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.192664\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.167725\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.257636\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.407771\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.120233\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.568987\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.368518\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.144802\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.364146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabbi/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0834, Accuracy: 9732/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.369172\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.200447\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.308870\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.252300\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.251543\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.377214\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.332738\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.148885\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.234457\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.316215\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.148085\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.242410\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.164923\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.229056\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.193724\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.189472\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.249401\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.390891\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.160126\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.272141\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.511072\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.360013\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.218439\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.238386\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.281042\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.194534\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.169779\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.225897\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.112217\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.179950\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.219810\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.220677\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.346966\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.216869\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.165959\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.364215\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.181949\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.181833\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.117185\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.242418\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.126637\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.165810\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.283062\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.378487\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.344626\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.151092\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.282731\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.168578\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.261244\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.350968\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.278436\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.274411\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.141939\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.082051\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.083232\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.161925\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.145767\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.222237\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.341409\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.241434\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.115001\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.267037\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.131889\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.352584\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.431463\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.377434\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.178317\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.386440\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.268201\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.147107\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.219584\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.131774\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.254047\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.414945\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.371624\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.139826\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.257249\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.385604\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.105681\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.191973\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.273876\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.292559\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.376066\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.237661\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.242688\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.111318\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.283025\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.487739\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.147631\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.326294\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.143208\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.128225\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.537664\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.103221\n",
      "\n",
      "Test set: Avg. loss: 0.0731, Accuracy: 9776/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.351814\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.116129\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.382456\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.201883\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.166344\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.344439\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.414137\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.184290\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.200059\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.098229\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.329669\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.206189\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.161796\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.241510\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.289160\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.194236\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.152211\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.156650\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.150754\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.581464\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.196854\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.289161\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.160795\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.173353\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.166356\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.235334\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.381944\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.141485\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.411684\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.108463\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.462303\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.283798\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.263208\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.105080\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.334794\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.127160\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.215485\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.104666\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.196901\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.351844\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.125743\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.363893\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.200514\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.201958\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.247476\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.236285\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.224510\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.225119\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.116493\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.084637\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.348739\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.159173\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.319290\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.095468\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.307228\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.098963\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.465366\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.321836\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.447656\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.120156\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.248703\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.130236\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.120084\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.122839\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.138720\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.260406\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.156692\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.135625\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.310055\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.295155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.198787\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.312376\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.099714\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.134273\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.246141\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.166203\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.169339\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.206162\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.200593\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.332015\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.149677\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.174510\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.285337\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.249406\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.533460\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.256123\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.103815\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.196737\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.229652\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.394346\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.284749\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.211784\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.217083\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.179146\n",
      "\n",
      "Test set: Avg. loss: 0.0694, Accuracy: 9784/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.280632\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.138442\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.140920\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.079117\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.092867\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.294171\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.076948\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.119801\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.381514\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.298400\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.177509\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.122418\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.319427\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.126394\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.139371\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.161948\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.094125\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.100763\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.064901\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.100166\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.098451\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.438584\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.193906\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.197124\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.189052\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.203904\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.171628\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.187514\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.224939\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.255543\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.254890\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.145516\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.207428\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.170557\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.166685\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.129099\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.316494\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.174675\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.174130\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.297099\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.177104\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.264396\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.137049\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.394070\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.207120\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.210537\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.215808\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.289122\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.280477\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.219467\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.304798\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.323358\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.222555\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.209839\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.544771\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.094456\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.162573\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.112463\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.255969\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.145527\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.101590\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.276131\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.168609\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.209622\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.283025\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.118751\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.074823\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.266394\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.177463\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.133127\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.221105\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.109292\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.031376\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.042806\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.106633\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.715308\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.110079\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.127517\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.146753\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.155066\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.253398\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.105473\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.180279\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.098285\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.090322\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.119523\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.485232\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.172734\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.156791\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.279140\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.149308\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.238051\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.409968\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.114600\n",
      "\n",
      "Test set: Avg. loss: 0.0641, Accuracy: 9806/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.344880\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.186483\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.141378\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.277485\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.122756\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.242373\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.275945\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.133391\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.063820\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.323803\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.162081\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.081139\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.115710\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.223722\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.204934\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.172512\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.186343\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.218529\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.181304\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.248291\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.244712\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.136315\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.111549\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.237427\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.236361\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.199156\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.128150\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.129371\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.163598\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.090916\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.281022\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.201438\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.241303\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.112811\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.147502\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.188957\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.179582\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.134004\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.260312\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.260110\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.172024\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.259596\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.154743\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.181545\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.128287\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.485721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.205131\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.154981\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.173722\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.211423\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.307653\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.105496\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.410929\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.482568\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.059454\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.297967\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.168002\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.272915\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.180842\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.132423\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.183996\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.124769\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.212398\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.234849\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.045358\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.309131\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.100061\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.161870\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.283366\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.188925\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.151060\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.077306\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.270873\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.145740\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.260131\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.145554\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.265177\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.294231\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.445352\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.231271\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.307288\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.092492\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.177024\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.097400\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.282774\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.202129\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.116311\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.191582\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.191008\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.313198\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.272003\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.178921\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.252419\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.384953\n",
      "\n",
      "Test set: Avg. loss: 0.0573, Accuracy: 9823/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,9):\n",
    "  test_counter.append(i*len(train_loader.dataset))\n",
    "  train(i)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAELCAYAAAAP/iu7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAADRUWwAANFRbAAA0f0/OX4mXCTo0ggAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8641e3b198>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86417c91d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(example_data[30][0])\n",
    "plt.show()\n",
    "output.data.max(1, keepdim=True)[1][30].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.0296,  1.1414,  2.7960,  2.7960,\n",
       "           2.2233, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.3733,  0.3395,  2.1723,  2.7833,  2.7833,  2.7833,\n",
       "           2.2105, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  1.0013,  2.7833,  2.7833,  2.7833,  2.7833,  2.7833,\n",
       "           2.5797,  0.5431, -0.2206, -0.2333, -0.1187,  1.6632,  1.6632,\n",
       "           1.6632,  1.6632,  1.6632,  1.6632,  0.4286, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.0551,  2.1851,  2.7833,  2.7833,  2.7833,  2.7833,  2.7833,\n",
       "           2.7833,  2.7833,  2.7960,  2.7833,  2.7833,  2.7833,  2.7833,\n",
       "           2.7833,  2.7833,  2.7833,  2.7833,  0.8868, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           0.8995,  2.7833,  2.7833,  2.7833,  2.7833,  2.7833,  2.7833,\n",
       "           2.7833,  2.7833,  2.7960,  2.7833,  2.7833,  2.7833,  2.7833,\n",
       "           2.7833,  2.7833,  2.7833,  2.7833,  0.8868, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.2587,\n",
       "           2.2869,  2.7833,  2.7833,  2.7833,  1.6123,  2.4015,  2.4015,\n",
       "           0.9504,  0.5177,  0.5177,  0.5177,  0.5177,  0.5177,  0.5177,\n",
       "           0.5177,  0.5177,  0.5177,  0.5177, -0.0424, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.1995,\n",
       "           2.4778,  2.7833,  2.7833,  2.7833,  2.6051,  1.2814, -0.3224,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           0.1740,  2.3760,  2.7833,  2.7833,  2.7833,  2.7833,  2.6178,\n",
       "           0.9504, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  0.0595,  1.2050,  2.3760,  2.7833,  2.7833,  2.7833,\n",
       "           2.6433,  2.0323, -0.0806, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.0296,  1.1159,  2.7833,  2.7833,\n",
       "           2.7833,  2.7833,  2.2487,  1.4723,  0.2504, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.2504,\n",
       "           1.7014,  2.7960,  2.8215,  2.7960,  1.4850, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.3224,  1.6887,  2.7960,  2.7833,  2.7451,  2.2233, -0.1187,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  0.2504,  1.4850,  2.7451,  2.7833,  2.7833, -0.0551,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242,  2.2233,  2.7833,  2.7833,  0.8359,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242,  2.2233,  2.7833,  2.7833,  1.8287,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.1951,  0.7468,  2.6178,  2.7833,  1.7014,  0.2377,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           0.8995,  2.1596,  2.7960,  2.7833,  2.7833,  1.2559, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.4978,\n",
       "           2.6051,  2.6051,  2.6051,  2.6051,  2.6051,  2.6051,  2.6051,\n",
       "           2.7324,  2.7833,  2.7960,  2.7833,  1.9178, -0.3224, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.1159,\n",
       "           2.2105,  2.5797,  2.7833,  2.7833,  2.7833,  2.7833,  2.7833,\n",
       "           2.7833,  2.7833,  2.7960,  1.8541, -0.1569, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  0.5431,  2.7833,  2.7833,  2.7833,  2.7833,  2.7833,\n",
       "           2.7833,  1.6505,  0.8995, -0.1951, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
