{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import PIL.ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from werkzeug.wrappers import Request, Response\n",
    "from flask import Flask\n",
    "from flask import render_template\n",
    "from flask import request\n",
    "from werkzeug.serving import run_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = pickle.load(open(\"network.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(im):\n",
    "    im = im.resize((28,28))\n",
    "    im = im.convert('L')\n",
    "        \n",
    "    pixels = im.load()\n",
    "    \n",
    "    for i in range(im.size[0]): # for every pixel:\n",
    "        for j in range(im.size[1]):\n",
    "            if pixels[i,j] < 100:\n",
    "                pixels[i,j] = 255\n",
    "            else:\n",
    "                pixels[i,j] = 0\n",
    "            #pixels[i,j] = 255-pixels[i,j]\n",
    "\n",
    "    plt.imshow(im)\n",
    "            \n",
    "    trans1 = transforms.ToTensor()\n",
    "    trans2 = transforms.Normalize((0.1307,), (0.3081,))\n",
    "    im = trans2(trans1(im))\n",
    "    \n",
    "    hello = im.numpy()\n",
    "    hello = np.expand_dims(hello, axis=0)\n",
    "    im = torch.from_numpy(hello)\n",
    "    \n",
    "    output = network(im)\n",
    "        \n",
    "    print(output)\n",
    "        \n",
    "    return output.data.max(1, keepdim=True)[1][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabbi/.local/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-13.0099,  -2.7441,  -0.2460,  -2.2320, -16.5284, -17.5768, -20.6751,\n",
      "          -3.8831,  -3.6535, -12.4789]], grad_fn=<LogSoftmaxBackward>)\n",
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = Image.open(\"9.jpg\")\n",
    "print(predict(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict_digit', methods=['POST'])\n",
    "def predict_digit():\n",
    "    encoded = request.form['encoded']\n",
    "    \n",
    "    im = Image.open(BytesIO(base64.b64decode(encoded)))\n",
    "            \n",
    "    return str(predict(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    run_simple('0.0.0.0', 9001, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
