{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import PIL.ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from werkzeug.wrappers import Request, Response\n",
    "from flask import Flask\n",
    "from flask import render_template\n",
    "from flask import request\n",
    "from werkzeug.serving import run_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = pickle.load(open(\"network.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(im):\n",
    "    im = im.resize((28,28))\n",
    "    im = im.convert('L')\n",
    "        \n",
    "    pixels = im.load()\n",
    "    \n",
    "    for i in range(im.size[0]): # for every pixel:\n",
    "        for j in range(im.size[1]):\n",
    "            if pixels[i,j] < 100:\n",
    "                pixels[i,j] = 255\n",
    "            else:\n",
    "                pixels[i,j] = 0\n",
    "            #pixels[i,j] = 255-pixels[i,j]\n",
    "\n",
    "    plt.imshow(im)\n",
    "            \n",
    "    trans1 = transforms.ToTensor()\n",
    "    trans2 = transforms.Normalize((0.1307,), (0.3081,))\n",
    "    im = trans2(trans1(im))\n",
    "    \n",
    "    hello = im.numpy()\n",
    "    hello = np.expand_dims(hello, axis=0)\n",
    "    im = torch.from_numpy(hello)\n",
    "    \n",
    "    output = network(im)\n",
    "        \n",
    "    print(output)\n",
    "        \n",
    "    return output.data.max(1, keepdim=True)[1][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -4.3670, -11.4438,  -9.7494, -10.9486, -10.9044,  -1.4255,  -0.5118,\n",
      "         -14.8601,  -1.9158,  -8.7960]], grad_fn=<LogSoftmaxBackward>)\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabbi/.local/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = Image.open(\"6.jpg\")\n",
    "print(predict(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict_digit', methods=['POST'])\n",
    "def predict_digit():\n",
    "    encoded = request.form['encoded']\n",
    "    \n",
    "    im = Image.open(BytesIO(base64.b64decode(encoded)))\n",
    "            \n",
    "    return str(predict(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:9000/ (Press CTRL+C to quit)\n",
      "/home/rabbi/.local/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "192.168.0.106 - - [14/Nov/2018 01:06:51] \"\u001b[37mPOST /predict_digit HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -3.8563, -18.8443, -14.3077, -14.4287, -20.7476,  -0.0580,  -3.4753,\n",
      "         -16.9230,  -5.4697, -12.3260]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.0.106 - - [14/Nov/2018 01:07:13] \"\u001b[37mPOST /predict_digit HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -3.8739, -15.8167, -12.8065, -13.3994, -13.4677,  -2.8433,  -0.0833,\n",
      "         -15.1383,  -7.0040, -10.1579]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.0.106 - - [14/Nov/2018 01:08:16] \"\u001b[37mPOST /predict_digit HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-14.2894, -10.1499, -10.0869,  -1.5889,  -3.4619,  -3.3720, -13.2224,\n",
      "         -13.4951,  -2.3336,  -0.4571]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.0.106 - - [14/Nov/2018 01:09:45] \"\u001b[37mPOST /predict_digit HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-26.0324, -22.2529, -18.4604, -21.4242,  -0.0002, -19.9242, -17.4135,\n",
      "         -20.2821, -15.3882,  -8.4462]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.0.106 - - [14/Nov/2018 01:10:22] \"\u001b[37mPOST /predict_digit HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-18.2941, -20.3638, -21.3381, -12.0697, -20.0332,  -0.0000, -13.7999,\n",
      "         -20.7096, -14.2839, -11.9303]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run_simple('0.0.0.0', 9000, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
